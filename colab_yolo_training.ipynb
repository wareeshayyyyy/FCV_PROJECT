{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLO Training - Bone Fracture Detection\n",
        "\n",
        "## Module 3: Object Detection Training\n",
        "\n",
        "Complete YOLOv8 training pipeline with 5-10 epochs on Google Colab GPU.\n",
        "\n",
        "## Features:\n",
        "- ‚úÖ Upload dataset from PC\n",
        "- ‚úÖ Free GPU access (T4, 16GB VRAM)\n",
        "- ‚úÖ Automatic model download\n",
        "- ‚úÖ Training visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dependencies installed!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "%pip install ultralytics opencv-python opencv-contrib-python scikit-image scipy -q\n",
        "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118 -q\n",
        "\n",
        "print(\"‚úÖ Dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "GPU INFORMATION\n",
            "============================================================\n",
            "CUDA Available: False\n",
            "‚ö†Ô∏è  No GPU! Go to: Runtime > Change runtime type > GPU\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Check GPU/CPU\n",
        "import torch\n",
        "print(\"=\"*60)\n",
        "print(\"DEVICE INFORMATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ CUDA Available: True\")\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"VRAM: {vram_gb:.2f} GB\")\n",
        "    print(\"‚úÖ GPU is ready for training!\")\n",
        "    recommended_model = 's' if vram_gb >= 8 else 'n'\n",
        "    recommended_batch = 16 if vram_gb >= 8 else 8\n",
        "    print(f\"Recommended: YOLOv8{recommended_model}, batch={recommended_batch}\")\n",
        "    device_type = \"GPU\"\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è  CUDA Available: False\")\n",
        "    print(\"‚úÖ CPU mode enabled - Training will work but will be slower\")\n",
        "    print(\"üí° Tip: For faster training, go to Runtime > Change runtime type > GPU (T4)\")\n",
        "    recommended_model = 'n'\n",
        "    recommended_batch = 4\n",
        "    device_type = \"CPU\"\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 2: Upload Dataset from PC\n",
        "\n",
        "Upload your dataset ZIP file from your computer:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload Dataset ZIP from PC\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"UPLOAD DATASET FROM PC\")\n",
        "print(\"=\"*80)\n",
        "print(\"üìÅ Select your dataset ZIP file...\")\n",
        "print(\"   (Should contain: train/, valid/, test/ folders with images and labels)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Create project directory\n",
        "project_dir = Path(\"/content/bone_fracture_detection\")\n",
        "project_dir.mkdir(exist_ok=True)\n",
        "data_dir = project_dir / 'data' / 'archive'\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "(project_dir / \"yolo_training_results\").mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\n‚úÖ Uploaded: {filename}\")\n",
        "    \n",
        "    # Extract if ZIP\n",
        "    if filename.endswith('.zip'):\n",
        "        print(f\"üì¶ Extracting {filename}...\")\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall(data_dir)\n",
        "        print(f\"‚úÖ Extracted to: {data_dir}\")\n",
        "        \n",
        "        # Find the dataset folder\n",
        "        extracted_folders = [f for f in data_dir.iterdir() if f.is_dir()]\n",
        "        if extracted_folders:\n",
        "            dataset_folder = extracted_folders[0]\n",
        "            print(f\"‚úÖ Dataset folder found: {dataset_folder.name}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  Please upload a ZIP file\")\n",
        "\n",
        "# Check if dataset exists\n",
        "dataset_path = None\n",
        "for possible_path in [\n",
        "    data_dir / \"bone fracture detection.v4-v4.yolov8\",\n",
        "    data_dir / \"BoneFractureYolo8\"\n",
        "]:\n",
        "    if possible_path.exists() and (possible_path / \"data.yaml\").exists():\n",
        "        dataset_path = possible_path\n",
        "        break\n",
        "\n",
        "# Also search recursively\n",
        "if not dataset_path:\n",
        "    for yaml_file in data_dir.rglob(\"data.yaml\"):\n",
        "        dataset_path = yaml_file.parent\n",
        "        break\n",
        "\n",
        "if dataset_path and (dataset_path / \"data.yaml\").exists():\n",
        "    print(f\"\\n‚úÖ Dataset ready at: {dataset_path}\")\n",
        "    print(f\"‚úÖ data.yaml found: {(dataset_path / 'data.yaml').exists()}\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  Dataset not found. Please upload the dataset ZIP file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 3: Training Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training Configuration\n",
        "import yaml\n",
        "\n",
        "# Find dataset path\n",
        "if not dataset_path:\n",
        "    for yaml_file in data_dir.rglob(\"data.yaml\"):\n",
        "        dataset_path = yaml_file.parent\n",
        "        break\n",
        "\n",
        "DATA_YAML = str(dataset_path / \"data.yaml\") if dataset_path else None\n",
        "\n",
        "# Auto-adjust based on device\n",
        "if torch.cuda.is_available():\n",
        "    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    if vram_gb >= 16:\n",
        "        MODEL_SIZE = \"m\"  # medium\n",
        "        BATCH = 32\n",
        "    elif vram_gb >= 8:\n",
        "        MODEL_SIZE = \"s\"  # small\n",
        "        BATCH = 16\n",
        "    else:\n",
        "        MODEL_SIZE = \"n\"  # nano\n",
        "        BATCH = 8\n",
        "else:\n",
        "    MODEL_SIZE = \"n\"  # nano for CPU\n",
        "    BATCH = 4  # Smaller batch for CPU\n",
        "\n",
        "EPOCHS = 10       # 5-10 epochs\n",
        "IMGSZ = 640       # Image size\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TRAINING CONFIGURATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Model: YOLOv8{MODEL_SIZE}\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Batch Size: {BATCH} (adjusted for {device_type})\")\n",
        "print(f\"Image Size: {IMGSZ}\")\n",
        "print(f\"Device: {device_type}\")\n",
        "print(f\"Dataset: {DATA_YAML}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Update Data YAML paths\n",
        "if DATA_YAML and Path(DATA_YAML).exists():\n",
        "    data_yaml_path = Path(DATA_YAML)\n",
        "    with open(data_yaml_path, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "    \n",
        "    base_dir = data_yaml_path.parent\n",
        "    data_config['train'] = str(base_dir / 'train' / 'images')\n",
        "    data_config['val'] = str(base_dir / 'valid' / 'images')\n",
        "    data_config['test'] = str(base_dir / 'test' / 'images')\n",
        "    \n",
        "    updated_yaml = base_dir / 'data_updated.yaml'\n",
        "    with open(updated_yaml, 'w') as f:\n",
        "        yaml.dump(data_config, f)\n",
        "    \n",
        "    DATA_YAML = str(updated_yaml)\n",
        "    print(f\"‚úÖ Data YAML updated: {updated_yaml}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Dataset not found: {DATA_YAML}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 4: Start YOLO Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start Training\n",
        "from ultralytics import YOLO\n",
        "\n",
        "if DATA_YAML and Path(DATA_YAML).exists():\n",
        "    print(\"=\"*80)\n",
        "    print(\"STARTING YOLO TRAINING\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"This will take ~2-5 hours for {EPOCHS} epochs...\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    model = YOLO(f\"yolov8{MODEL_SIZE}.pt\")\n",
        "    \n",
        "    results = model.train(\n",
        "        data=DATA_YAML,\n",
        "        epochs=EPOCHS,\n",
        "        imgsz=IMGSZ,\n",
        "        batch=BATCH,\n",
        "        device=0 if torch.cuda.is_available() else 'cpu',\n",
        "        project=str(project_dir / \"yolo_training_results\"),\n",
        "        name=f\"yolov8{MODEL_SIZE}_bone_fracture\",\n",
        "        save=True,\n",
        "        save_period=2,\n",
        "        val=True,\n",
        "        plots=True,\n",
        "        verbose=True,\n",
        "        seed=42,\n",
        "        amp=True\n",
        "    )\n",
        "    \n",
        "    print(\"\\n‚úÖ Training Complete!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Cannot start training - dataset not found!\")\n",
        "    print(\"Please upload dataset in Step 2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: View Results & Download Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View Results & Download Model\n",
        "from IPython.display import Image, display\n",
        "from google.colab import files\n",
        "\n",
        "results_dir = project_dir / \"yolo_training_results\" / f\"yolov8{MODEL_SIZE}_bone_fracture\"\n",
        "best_model = results_dir / \"weights\" / \"best.pt\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TRAINING RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if best_model.exists():\n",
        "    print(f\"‚úÖ Best model: {best_model}\")\n",
        "    \n",
        "    # Display results\n",
        "    try:\n",
        "        display(Image(f\"{results_dir}/results.png\"))\n",
        "        display(Image(f\"{results_dir}/confusion_matrix.png\"))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Could not display images: {e}\")\n",
        "        print(f\"Results available in: {results_dir}\")\n",
        "    \n",
        "    # Download\n",
        "    files.download(str(best_model))\n",
        "    print(\"‚úÖ Model downloaded!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Model not found - training may still be in progress\")\n",
        "    print(f\"Expected location: {best_model}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
